
Prof Hiroshi Ishiguro – director, Intelligent Robotics Laboratory at Osaka 
University, Japan, and named one of thetop 100 living geniuses by Synetics 
<http://www.telegraph.co.uk/news/uknews/1567544/Top-100-living-geniuses.html> 
in 2007 – is a very busy man. So busy, he practically needs a clone to keep up 
with his work schedule, something many of us have wished for in our own lives.

But Ishiguro created one – a near-perfect mechanical likeness of silicon skin, 
actuators, electronics and his own hair – which he operates remotely via the 
internet. It means Ishiguro can (almost) be in two places at once: he regularly 
sends his robot to give lectures at conferences around the world. “It’s very 
convenient,” he deadpans.

The future of healthcare: AI, augmented reality and drug-delivering drones
 Read more  
<https://www.theguardian.com/sustainable-business/2016/nov/01/the-future-of-healthcare-ai-augmented-reality-and-drug-delivering-drones>
Of course, his robot can’t answer questions – he has to do that himself – but 
the lecture is automated. Although his robot remains seated, it speaks in his 
voice, and his likeness is readily accepted by others – more readily, in fact, 
than he can accept this simulacrum of himself.

It is, he says, like having a twin brother, only odder. Looking at his 
android, he says, is more like seeing a photograph than his own mirror image. 
“That is a very strange feeling – I cannot accept the android face as my face. 
But other people, they completely accept the android face as my face.”

Ishiguro, who will be in Melbourne next week for the Creative Innovation 2016 
<http://www.creativeinnovationglobal.com.au/ci2016/welcome/> conference, 
specialises in the study of human-robot interaction, and human-like or social 
robots are the subject of his experiments which ask deep questions of humanity 
itself. In other words, by studying robots, we can learn more about ourselves.

Social robots, like his own doppelganger, are likely to soon be integrated 
into both our home and working lives, something that has obvious implications 
for employment and social welfare.Reports say 
<http://www.ceda.com.au/research-and-policy/policy-priorities/workforce> that 
within the next 10 to 20 years, up to 40% of the Australian workforce might be 
replaced by automation. That’s more than five million jobs. Androids couldsoon 
be employed 
<https://www.msn.com/en-us/money/careersandeducation/21-jobs-where-robots-are-already-replacing-humans/ss-BBv6yiU#image=1>
 as receptionists, tour guides, evensurgeons 
<https://www.theguardian.com/sustainable-business/2016/jul/23/nhs-robots-doctors-hospital-surgery-staff>
.

Despite their oddness, robots could have some advantages in roles normally 
performed by humans. For example, Ishiguro’s robots may be used to test for 
autism in children. “Human eye movement is very complicated,” he says. “Kids 
with autism cannot focus or gaze on the human’s eyes. But they can gaze on the 
android’s eyes. So this is another form of cognitive science, and maybe 
neuroscience.”
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Fsustainable-business%2F2016%2Fnov%2F03%2Fandroid-clone-v-human-will-you-be-able-to-tell-the-difference-at-work%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-2%23img-2&picture=https%3A%2F%2Fmedia.guim.co.uk%2F6c76e5583fc84560b21080ebc15bf2f2e00bd7cb%2F0_0_3440_4586%2F3440.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=Android%20clone%20v%20human%3A%20will%20you%20be%20able%20to%20tell%20the%20difference%20at%20work%3F&url=https%3A%2F%2Fwww.theguardian.com%2Fsustainable-business%2F2016%2Fnov%2F03%2Fandroid-clone-v-human-will-you-be-able-to-tell-the-difference-at-work%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-2%23img-2>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=Android%20clone%20v%20human%3A%20will%20you%20be%20able%20to%20tell%20the%20difference%20at%20work%3F&url=https%3A%2F%2Fwww.theguardian.com%2Fsustainable-business%2F2016%2Fnov%2F03%2Fandroid-clone-v-human-will-you-be-able-to-tell-the-difference-at-work%3Fpage%3Dwith%3Aimg-2%23img-2&media=https%3A%2F%2Fmedia.guim.co.uk%2F6c76e5583fc84560b21080ebc15bf2f2e00bd7cb%2F0_0_3440_4586%2F3440.jpg>
 Prof Hiroshi Ishiguro with Erica, his latest humanoid robot. Photograph: 
Justin McCurry for the Guardian 
Similarly, experiments show the elderly – particularly those afflicted by 
dementia – may relate better to robots than to their human caregivers. The 
inbuilt paranoia of humans means we are hard-wired to danger: “Always, we think 
about [our] interlocuter’s deeper intentions,” Ishiguro says. Machines are 
simply easier to trust.

I ask if a robotic caregiver might lack, well, a human touch. Ishiguro’s 
response (which may be somewhat compromised by language barriers and less than 
perfect phone reception) is unintentionally comical. “Human touch? What do you 
mean?”

When rephrased – isn’t empathy the most difficult human emotion to replicate? 
– Ishiguro misinterprets it as a technological problem; in particular, the 
production of robust human-like skin. “People may expect to use the android for 
more than 10 years, but usually we need to replace our sort of skin made by 
silicon every three years. So I think that is kind of a bottleneck of android 
technologies.”

Why your NHS surgeon could be a robot in the future
 Read more  
<https://www.theguardian.com/sustainable-business/2016/jul/23/nhs-robots-doctors-hospital-surgery-staff>
But Ishiguro knows perfectly well that for robots to be accepted in human 
society, particularly in the workforce, we need to be able to get along with 
them. Empathise with them, even. And that means making them look and behave 
more like us.

In the not too distant future, we may struggle to tell the difference. “Of 
course, we are improving the android technology every year and we are improving 
the materials and the facial expressions and features,” he says. He cites an 
experiment with an android receptionist used in a company in Japan.

“Eighty per cent of people couldn’t [tell the difference], they just said 
hello to the android,” he says. “The other 20% of people, maybe they thought 
there was something wrong, maybe not human. But the technology can cheat 80% of 
people if the android behaves like a receptionist. A receptionist is quite 
simple.”

Even emotions, he says, may not be so difficult to replicate eventually, even 
empathy. “It’s programmable, and the robot can imitate the human feelings. But 
feelings [are] deep questions for humans … We use so many ambiguous words for 
humans – consciousness, heart. In order to deeply understand what these words 
mean, we need a mirror to reflect humanity.”

A mirror? Or perhaps the less appealing photographic image like his android 
clone? “I think it will be very confusing,” he admits.

Prof Hiroshi Ishiguro will speak at Creative Innovation 2016 
<http://www.creativeinnovationglobal.com.au/ci2016/>, which will be in 
Melbourne from 7 to 9 November



 