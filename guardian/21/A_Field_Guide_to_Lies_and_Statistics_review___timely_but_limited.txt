
Politics has always required lies, but it’s hard to think of a democratic 
leader who has lied so brazenly and so constantly asDonald Trump 
<https://www.theguardian.com/us-news/donaldtrump>. The burning question is 
whether his supporters think his blatant fibs are true or don’t much care 
whether they are or not.

While neuroscientist Daniel Levitin was writing this book, “post-truth” and 
“fake news” were not yet common currency. Does that make it extraordinarily 
timely, or redundant? Probably neither. As a lucid guide to critical thinking 
about statistics, information and assertion, it’s profoundly welcome. If anyone 
thinks it is the antidote to our age of unreason, they are deluded.

It’s strange to find little discussion of the cognitive factors that confound 
our analysis of the facts

So seismic have been the changes manifested in democratic political sentiment 
since last summer that already parts ofA Field Guide read like a quaint 
historical document. It makes just one reference to the US presidential 
campaign. It exposes the falsehood of Trump’s claim that “thousands and 
thousands” of Muslims in Jersey City cheered as the World Trade Center 
crumbled, but “balances” this by acknowledging that Hillary Clinton’sclaim that 
all her grandparents were immigrants is untrue 
<http://www.politifact.com/truth-o-meter/statements/2015/apr/16/hillary-clinton/hillary-clinton-flubs-familys-immigration-history-/>
. This now reads like the sort of normalisation that permitted the staggering, 
unabashed dishonesty of the Trump (and in the UK, the Brexit Leave) campaign.

That’s the dilemma in Levitin’s mission. His scientific dissection of lies and 
statistics would seem compromised if he appeared to take sides. He is simply 
concerned with penetrating to the facts, which means exposing common forms of 
misrepresentation and misconception. He shows how graphs can be designed to 
mislead, why probabilities often defy our intuition, why coincidences are 
inevitable, why we should check the authority of sources and evaluate claims in 
the light of, not in isolation from, what we already know to be true.

Even “experts” make basic mistakes in deductive reasoning. A poor grasp of 
probability theory <https://www.theguardian.com/society/2005/jul/06/NHS.uknews> 
in the testimony of paediatrician Roy Meadow prompted the conviction of Sally 
Clark for murder in 1999 after both her children suffered cot death. Yet 
Levitin leaves no doubt that to leap from such errors to aGove-style distrust 
<https://www.theguardian.com/politics/blog/2016/jun/08/experts-eu-referendum-michael-gove>
 of all expert advice would be idiotic. As he says, “critical thinking doesn’t 
mean we disparage everything” (except what suits us).

All this is excellent. But A Field Guide feels rooted in the deficit model of 
decision-making, which holds that bad judgements and mistakes stem from a lack 
of knowledge. Jonathan Swift understood that fallacy, saying that you will 
never reason a person out of an opinion they never reasoned themselves into.

It’s strange, then, to find – from an author so well versed in cognitive 
science – little discussion of the cognitive factors that confound our analysis 
of the facts. PsychologistsDaniel Kahneman 
<https://www.theguardian.com/science/2014/feb/16/daniel-kahneman-thinking-fast-and-slow-tributes>
 andAmos Tversky 
<https://www.theguardian.com/science/2014/feb/16/daniel-kahneman-thinking-fast-and-slow-tributes>
 crop up only to relate an anecdote, not for their groundbreaking notion that 
the mind uses two modes of decision-making: a rare, logical, effortful “slow” 
mode of the kind Levitin commends, and a more frequent, emotional, intuitive 
“fast” mode. This is not because we are mostly foolish, impulsive thinkers. 
There are sound evolutionary benefits to a quick but less-reliable system.

There is also now a vast body of research on the cognitive biases 
<https://www.theguardian.com/news/oliver-burkeman-s-blog/2014/feb/28/bias-political-psychology-burkeman-blog>
 that threaten to distort even the most considered of judgments, including many 
findings reported in the scientific literature. In particular, we believe more 
readily what fits our preconceptions and block out contradictory evidence.

Related: Trump’s personality will help us learn how our minds work | Deborah 
Orr 
<https://www.theguardian.com/commentisfree/2016/dec/30/donald-trump-personality-disorders-learn-minds-work>

Such biases surely played a role in letting Trump lie with such abandon. It’s 
not that his followers believed him, exactly – rather, there was too neat a fit 
with what they wanted to hear, as Trump doubtless knew. The current threats to 
liberalism, rationality, expertise and informed debate come less from a failure 
to process and assess facts than from our predisposition to accept a particular 
narrative. Levitin asserts that “Many people think ‘If I found it online it 
must be true’” – but that’s more likely if it confirms rather than challenges 
our prejudice.

In the spirit of Levitin’s nullius in verba 
<https://en.wikipedia.org/wiki/Nullius_in_verba>, I propose an experiment. We 
pick a random sample of US citizens (Levitin tells us how non-trivial it is to 
do that, as well as explaining how big a sample we need to be confident in the 
conclusions) and see whether those who read this book are more immune to 
Trump’s lies than a control group who do not. I’d love to think they would be, 
but I doubt it. 

• A Field Guide to Lies and Statistics by Daniel Levitin is published by 
Viking (£14.99). To order a copy for £11.99 go tobookshop.theguardian.com 
<https://bookshop.theguardian.com/field-guide-to-lies-and-statistics.html?utm_source=editoriallink&utm_medium=merch&utm_campaign=article>
 or call 0330 333 6846. Free UK p&p over £10, online orders only. Phone orders 
min p&p of £1.99
 