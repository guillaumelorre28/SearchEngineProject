
Microsoft <https://www.theguardian.com/technology/microsoft> workers on the 
“online safety team” were forced to view photos and videos of “indescribable 
sexual assaults”, “horrible brutality”, murder and child abuse, resulting in 
severe post-traumatic stress disorder, according to a lawsuit.

The complaint, filed on behalf of two employees and their families, outlined 
the “inhumane and disgusting content” the moderators viewed on a regular basis 
and alleged that the psychological impact has been so extreme that the men are 
“triggered” by simply seeing children and can no longer use computers without 
breaking down.

The lawsuit, which accused Microsoft of “negligent infliction of emotional 
distress”, provides a window into the often secretive world of online 
moderation and sheds light on the intense suffering of tech workers responsible 
for detecting and reporting digital content “designed to entertain the most 
twisted and sick minded people in the world”.

“It’s horrendous,” said Ben Wells, one of the attorneys who filed the suit in 
Washington state <https://www.theguardian.com/us-news/washington-state>, where 
Microsoft is headquartered. “It’s bad enough just to see a child get sexually 
molested. Then there are murders. Unspeakable things are done to these 
children.”

If the suit prevails, it could have ramifications for corporations across the 
industry, and Wells said he hopes the case inspires others to speak out about 
poor working conditions.

A Microsoft spokesperson said in a statement that the company “disagrees” with 
the claims in the suit and “takes seriously its responsibility to remove and 
report imagery of child sexual exploitation and abuse being shared on its 
services, as well as the health and resiliency of the employees who do this 
important work”.

Plaintiffs Henry Soto and Greg Blauert both worked on the online safety team, 
which is responsible for complying with legislation passed in 2008 requiring 
tech companies to report child abuse images and other crimes.

Microsoft did not warn the workers about the dangers of this line of work and 
the potential for “debilitating injuries”, according to the suit, which was 
filed in December and was publiclyreported 
<http://courthousenews.com/workers-on-porn-detail-sue-microsoft-for-injuries/> 
this week.

When Soto was “involuntarily transferred” to the unit in 2008, he had 
“God-like” status, which meant he could view any customer’s communications, the 
suit said. His job involved assisting law enforcement in breaking up “crime 
rings” and “violent groups” and required him to view “many thousands of 
photographs and videos” of violence and brutality.

“Many people simply cannot imagine what Mr Soto had to view on a daily basis 
as most people do not understand how horrible and inhumane the worst people in 
the world can be,” his lawyers wrote. Blauert, who was hired as a full-time 
employee in 2012, was also required to “review thousands of images of child 
pornography, adult pornography and bestiality that graphically depicted the 
violence and depravity of the perpetrators.”

[Soto] suffered from an internal video screen in his head and could see 
disturbing images

Although Microsoft created a “wellness program” and offered a counselor, the 
services were insufficient and ineffective and the company failed to help the 
workers understand the “vicarious trauma” and PTSD they were suffering, 
according to the suit.

Program authorities advised the workers to take walks and smoke breaks and 
suggested Blauert play video games to manage his symptoms, the complaint said. 
Later, however, his supervisors allegedly gave him a poor evaluation for “lack 
of production and too much time playing video games”.

When Soto initially met with psychiatrists, he said he was experiencing sleep 
disturbances, nightmares, anxiety and “suffered from an internal video screen 
in his head and could see disturbing images”. As time progressed, he began 
experiencing visual hallucinations, panic attacks in public, disassociation and 
depression.

“One of the triggers for him is children,” Wells told the Guardian. “At times, 
he can’t look at his own son … He can’t see a knife in the kitchen … He can’t 
look at computers.”

Soto eventually went on medical leave. 

Blauert suffered a physical and mental breakdown in 2013 when he was 
experiencing “intractable crying, insomnia, anxiety and PTSD”, the suit said. 
He is now triggered by adults who look like “potential abusers” and “fears for 
the safety of children he meets”. He is also unable to look at any “child 
related content” on computers and has not returned to work due to the triggers, 
according to the complaint.

The men are seeking damages, and the complaint also outlined potential reforms 
that would make the “online safety” job less harmful. That includes mandatory 
rotations out of the program, more time off, weekly meetings with a 
psychologist and a spousal wellness program.

Microsoft declined to comment on the specific claims, but said in a statement: 
“The health and safety of our employees who do this difficult work is a top 
priority.”

The corporation also said it provides mandatory psychological support each 
month, uses technology to “reduce the realism of the imagery”, reassigns 
employees who no longer want to do this work, and limits the amount of time the 
employees spend on the moderation.

Microsoft and other tech corporations need to do a much better job “protecting 
people who are doing heroic work”, added Wells. “They saved children’s lives. 
They put people in jail that deserved to be in jail.”

The attorney said he believes other tech corporations have similar challenges 
and inadequate or nonexistent wellness programs. In recent years, there have 
been past reports ofalarming conditions 
<https://www.wired.com/2014/10/content-moderation/> for moderators who review 
Facebook, Twitter,YouTube and other companies 
<http://www.nytimes.com/2010/07/19/technology/19screen.html>. 

“The public needs to understand that this work is not being done by a 
computer,” Wells said.
 