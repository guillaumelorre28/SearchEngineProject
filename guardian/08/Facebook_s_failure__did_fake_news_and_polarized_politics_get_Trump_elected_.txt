
“If I were to run, I’d run as a Republican. They are the dumbest group of 
voters in the country. They believe anything on Fox News. I could lie and 
they’d still eat it up. I bet my numbers would be terrific.”


Many Guardian readers will have seen this quote, attributed to a 1998 
interview withDonald Trump <https://www.theguardian.com/us-news/donaldtrump> in 
People magazine, in their Facebook news feed.

Facebook's fake news: Mark Zuckerberg rejects 'crazy idea' that it swayed 
voters
 Read more  
<https://www.theguardian.com/technology/2016/nov/10/facebook-fake-news-us-election-mark-zuckerberg-donald-trump>
It’s a great quote, but he never said it 
<http://www.snopes.com/1998-trump-people-quote/>.

It typifies the kind of fake news and misinformation that has plagued the 2016 
election on an unprecedented scale. In the wake of the surprise election of 
Donald Trump as president of the United States, pressure is growing onFacebook 
<https://www.theguardian.com/technology/facebook> to not only tackle the 
problem but also to find ways to encourage healthier discourse between people 
with different political views.

Rather than connecting people – as Facebook’s euphoric mission statement 
claims – the bitter polarization of the social network over the last eighteen 
months suggests Facebook is actually doing more to divide the world.
Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2016%2Fnov%2F10%2Ffirst-actions-trump-president-video&picture=>
Twitter  
<https://twitter.com/intent/tweet?text=What%20will%20be%20the%20first%20actions%20Trump%20takes%20as%20president%3F%20%E2%80%93%20video&url=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2016%2Fnov%2F10%2Ffirst-actions-trump-president-video>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=What%20will%20be%20the%20first%20actions%20Trump%20takes%20as%20president%3F%20%E2%80%93%20video&url=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2016%2Fnov%2F10%2Ffirst-actions-trump-president-video&media=>
What will be the first actions Trump takes as president? 
<https://www.theguardian.com/us-news/video/2016/nov/10/first-actions-trump-president-video>
“People have unfriended friends and family members because the style of 
discourse is so harsh,” said Claire Wardle, research director at the Tow Center 
for Digital Journalism. “Facebook stumbled into the news business without 
systems, editorial frameworks and editorial guidelines, and now it’s trying to 
course-correct.”


Facebook will need to change its business model if it does want to address 
these editorial challenges. Currently, the truth of a piece of content is less 
important than whether it is shared, liked and monetized. These “engagement” 
metrics distort the media landscape, allowing clickbait, hyperbole and 
misinformation to proliferate. And on Facebook’s voracious news feed, the 
emphasis is on the quantity of posts, not spending time on powerful, 
authoritative, well-researched journalism.

The more we click, like and share stuff that resonates with our own world 
views the more Facebook feeds us with similar posts. This has progressively 
divided the political narrative into two distinct filter bubbles – one for 
conservatives and one for liberals (a blue feed and a red feed 
<http://graphics.wsj.com/blue-feed-red-feed/>), pulling further and further 
apart in the run-up to election day.

‘Dust cloud of nonsense’


These information bubbles didn’t burst on 8 November, but the election result 
has highlighted how mainstream media and polling systems underestimated the 
power of alt-right news sources and smaller conservative sites that largely 
rely on Facebook to reach an audience. ThePew Research Center 
<http://www.niemanlab.org/2016/05/pew-report-44-percent-of-u-s-adults-get-news-on-facebook/>
 found that 44% of Americans get their news from Facebook.

Within Facebook’s digital echo chamber, misinformation that aligns with our 
beliefs spreads like wildfire

Yet fake news is not a uniquely Republican problem. An analysis by BuzzFeed 
<https://www.buzzfeed.com/craigsilverman/partisan-fb-pages-analysis> found that 
38% of posts shared from three large rightwing politics pages on Facebook 
included “false or misleading information” and that three large leftwing pages 
did the same 19% of the time.

What is a uniquely Republican problem is the validation given to fake news by 
the now president-elect. Trump has routinely repeated false news stories and 
whipped up conspiracy theories – whether that’squestioning Obama’s heritage 
<https://www.theguardian.com/us-news/2015/sep/18/trump-fails-to-correct-questioner-who-calls-obama-muslim-and-not-even-american>
,calling climate change a hoax 
<https://www.theguardian.com/us-news/2016/jul/12/donald-trump-climate-change-science-sierra-club>
 or questioning “crooked”Hillary Clinton’s health 
<https://www.theguardian.com/us-news/2016/sep/14/trump-clinton-health-medical-records-ohio-rally>
 – during high-profile rallies, while urging his followersnot to trust corrupt 
traditional media 
<https://www.theguardian.com/us-news/2016/aug/14/donald-trump-crooked-media-campaign-polls-free-press-hillary-clinton>
.

The conspiracy theories are amplified by a network of highly partisan media 
outlets with questionable editorial policies, including a website called the
Denver Guardian peddling stories about Clinton murdering people 
<http://www.denverpost.com/2016/11/05/there-is-no-such-thing-as-the-denver-guardian/>
 and a cluster of pro-Trump sitesfounded by teenagers in Veles, Macedonia 
<https://www.theguardian.com/technology/2016/aug/24/facebook-clickbait-political-news-sites-us-election-trump>
, motivated only by the advertising dollars they can accrue if enough people 
click on their links.

The situation is so dire that this week President Obama spoke about 
<http://www.sfgate.com/technology/businessinsider/article/OBAMA-Fake-news-on-Facebook-is-creating-a-dust-10599422.php>
 the “crazy conspiracy theorizing” that spreads on Facebook, creating a “dust 
cloud of nonsense”.
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-2%23img-2&picture=https%3A%2F%2Fmedia.guim.co.uk%2Ff7f52d865b6a9eb2e3dab01e3a2be950d8840bbb%2F0_140_4096_2457%2F4096.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-2%23img-2>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3Fpage%3Dwith%3Aimg-2%23img-2&media=https%3A%2F%2Fmedia.guim.co.uk%2Ff7f52d865b6a9eb2e3dab01e3a2be950d8840bbb%2F0_140_4096_2457%2F4096.jpg>
 Newspapers used to be the gatekeepers of news. Now 44% of Americans get their 
news from Facebook, according to one study. Photograph: Alba Vigaray/EPA 
“There is a cottage industry of websites that just fabricate fake news 
designed to make one group or another group particularly riled up,” said Fil 
Menczer, a professor at Indiana University who studies the spread of 
misinformation. “If you like Donald Trump and hate Hillary Clinton it’s easy 
for you to believe a fake piece of news about some terrible thing Hillary has 
done. These fake news websites often generate the same news just changing the 
name to get people on either side to be outraged.”

Menczer and his Indiana University colleagues hope to better understand how 
fake news, and how pieces debunking fake news, spread through social media by 
launching a range of analytical, non-profittools 
<http://cnets.indiana.edu/blog/2016/03/04/hoaxy/> later this year. 


Looking for what we want to hear

The misinformation being spread doesn’t always involve outlandish conspiracy 
theories. There’s a long tail of insidious half truths and misleading 
interpretations that fall squarely in the grey area, particularly when dealing 
with complex issues like immigration, climate change or the economy.


“Not everything is true or false, and in the gaps between what we can check 
and what is missing from our control we can create a narrative,” said Italian 
computer scientist Walter Quattrociocchi, who has studied the spread of false 
information. “Trump won at this. He was able to gather all the distrust in 
institutional power by providing an option for people looking for a change.”

“These things are very hard to detect automatically if they are true or not,” 
said Menczer. “Even professional fact-checkers can’t keep up.”
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-3%23img-3&picture=https%3A%2F%2Fmedia.guim.co.uk%2F3552de1975953bc3957f6b905daf28731068162e%2F0_161_2399_1439%2F2399.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-3%23img-3>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3Fpage%3Dwith%3Aimg-3%23img-3&media=https%3A%2F%2Fmedia.guim.co.uk%2F3552de1975953bc3957f6b905daf28731068162e%2F0_161_2399_1439%2F2399.jpg>
 Donald Trump on election night. Facebook’s algorithm means people are more 
likely to see stories with political viewpoints that match their own. 
Photograph: Mike Segar/Reuters 
According to Menczer’s research there’s a lag of around 13 hours 
<https://firstdraftnews.com/recent-research-reveals-false-rumours-really-do-travel-faster-and-further-than-the-truth/>
 between the publication of a false report and the subsequent debunking. That’s 
enough time for a story to be read by hundreds of thousands if not millions of 
people. Within Facebook’s digital echo chamber, misinformation that aligns with 
our beliefs spreads like wildfire, thanks to confirmation bias.

“People are more prone to accept false information and ignore dissenting 
information,” saidQuattrociocchi <https://www.imtlucca.it/walter.quattrociocchi>
. “We are just looking for what we want to hear.”

If you like Trump and hate Clinton it’s easy to believe a fake piece of news 
about some terrible thing Hillary has done
Fil Menczer, professor 
It’s a quirk of human psychology that the UK Independence party (Ukip) toyed 
with during the campaign for Britain to leave the EU. Arron Banks, Ukip’s 
largest donor, told the Guardian thatfacts weren’t necessary for winning 
<https://www.theguardian.com/politics/2016/jun/29/leave-donor-plans-new-party-to-replace-ukip-without-farage>
. “It was taking an American-style media approach. What they said early on was 
‘facts don’t work’ and that’s it. You have got to connect with people 
emotionally. It’s the Trump success.”

While it’s human nature to believe what we want to hear, Facebook’s algorithms 
reinforce political polarization. “You are being manipulated by the system [for 
falling for the fake news] and you become the perpetrator because you share it 
to your friends who trust you and so the outbreak continues,” saidMenczer 
<http://cnets.indiana.edu/fil/>.

It’s a perfect feedback loop. So how do you break it? Menczer says the 
solution is to create a filter. Before social media, the filter was provided by 
media companies, who acted as gatekeepers to the news and had staff trained in 
fact-checking and verifying information. In an age of budget cuts in 
traditional media, and the rise of clickbait and race-to-the-bottom journalism, 
standards have slipped across the board.

“Now the filter is us. But that’s not our job so we’re not good at it. Then 
the Facebook algorithm leverages that and amplifies the effect,” said Menczer.
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-4%23img-4&picture=https%3A%2F%2Fmedia.guim.co.uk%2F9d13b67c5c6cdaa594956295ae4884d9ca7b4441%2F0_25_3700_2221%2F3700.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-4%23img-4>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=Facebook%E2%80%99s%20failure%3A%20did%20fake%20news%20and%20polarized%20politics%20get%20Trump%20elected%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Fnov%2F10%2Ffacebook-fake-news-election-conspiracy-theories%3Fpage%3Dwith%3Aimg-4%23img-4&media=https%3A%2F%2Fmedia.guim.co.uk%2F9d13b67c5c6cdaa594956295ae4884d9ca7b4441%2F0_25_3700_2221%2F3700.jpg>
 A story about Hillary Clinton murdering people was among the conspiracy 
theories spread on Facebook during the election. Photograph: Justin 
Sullivan/Getty Images 
And so we come back to the algorithm.

Despite continually insisting that it’s a neutral technology platform and not 
a media company, Facebook is all-too aware of the influence it has to drive 
footfall to the polling stations.

Around 340,000 extra people turned out to vote in the 2010 US congressional 
elections because of a single election-day Facebook message, according to a 
studypublished in Nature 
<http://www.nature.com/news/facebook-experiment-boosts-us-voter-turnout-1.11401>
.

In a separate study the social networking site worked out how to make people 
feel happier or sadder by manipulating the information posted on 689,000 users’ 
news feeds. It found it could make people feel more positive of negative 
through a process of “emotional contagion 
<https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds>
”.

So what should Facebook do? It’s certainly not going to be easy. It has tried 
– and failed – to get a grip on the problem before, launching atool to let 
users report false information 
<https://www.theguardian.com/technology/2015/jan/21/facebook-news-feed-hoaxes-spam>
 in January 2015. (That ultimately failed because it relied on users, who 
turned out not to be very good at spotting fake news and also to falsely report 
a story as “fake” if they didn’t agree with it.) In September 2016, the company
joined a coalition 
<https://www.theguardian.com/media/2016/sep/13/facebook-twitter-social-media-newsgathering>
, along with Twitter, to improve the quality of reporting on social media and 
cut down on fake news. We have yet to see the fruits of this alliance.


Human v automated editors

In the interim, Facebook found itself in trouble over the team of humans who 
were curating its trending news section.According to a former journalist 
<http://gizmodo.com/former-facebook-workers-we-routinely-suppressed-conser-1775461006>
 who worked on the project, the team was routinely told to suppress news 
stories of interest to conservative readers. The company was widely criticized 
for playing the role of censor and being biased against Republicans.

Facebook is a source of news for billions of people. If that’s not a media 
organization, I don’t know what is
Dave McClure, investor 
That led Facebook to fire the editors and let the algorithm decide what’s 
trending. Since then fake news hasrepeatedly found its way into the highly 
influential trending list 
<https://www.washingtonpost.com/news/the-intersect/wp/2016/10/12/facebook-has-repeatedly-trended-fake-news-since-firing-its-human-editors/>
.

“Instead of hiring more editors to check the facts, they got rid of the 
editors and now they are even more likely to spread misinformation,” said 
Menczer. “They don’t see themselves as a media company and they run the risk of 
being told they are picking sides. They are in a tough spot, but they are also 
making a lot of money.”

Facebook’s continued rejection of the idea that it is a media company doesn’t 
sit well with some critics. “It sounds like bullshit,” said high-profile 
investor Dave McClure, speaking from the Web Summit in Lisbon a few hours after 
anexpletive-filled on-stage rant about Trump 
<https://twitter.com/adrianweckler/status/796340770282307584>. “It’s clearly a 
source of news and information for billions of people. If that’s not a media 
organization then I don’t know what is.”
Adrian Weckler (@adrianweckler) 
Wow, @davemcclure <https://twitter.com/davemcclure> has a MELTDOWN on 
#WebSummit <https://twitter.com/hashtag/WebSummit?src=hash> stage over Donald 
Trump electionpic.twitter.com/aRJmFpYyQA <https://t.co/aRJmFpYyQA>
 <https://twitter.com/adrianweckler/status/796340770282307584> November 9, 2016
 <https://twitter.com/adrianweckler/status/796340770282307584> 
He added that technology entrepreneurs have a responsibility to enable a “more 
well-rounded experience” for their audiences. “A lot of them are only thinking 
about how to make money. Maybe we need to mix in having ethics and principles 
and caring about the fact that people have a reasonable and rational experience 
of the information they process. Although that sounds a little too utopian.”

One solution could be to try to reduce the effect of filter bubbles by showing 
users a wider variety of opinions than their own. Even if people have a 
tendency to reject those opinions, at least they’ll be exposed to a diversity 
of views.

Wardle suggests that to tackle fake news, Facebook could introduce a mechanism 
to allow fact checking organisations to report false stories to Facebook so 
they don’t continually circulate. “Of course, people will shout censorship, so 
maybe Facebook could choose to change the way it display certain stories 
instead,” she said.

Facebook fires trending team, and algorithm without humans goes crazy
 Read more  
<https://www.theguardian.com/technology/2016/aug/29/facebook-fires-trending-topics-team-algorithm>
This is problematic because Facebook would have to manipulate the algorithm to 
make it less likely you would see something from a site categorized as 
disreputable. This would potentially involve discounting content your friends 
were interested in. “Then we would not like the platform as much because we 
like seeing stuff our friends are liking and sharing,” said Menczer.

All of these issues point towards the inevitability of Facebook acknowledging 
that it’s no longer just a technology company, but a media company –the media 
company.


In Mark Zuckerberg’s first Facebook update post-election, he talked about the 
need for everyone to work together. “We are all blessed to have the ability to 
make the world better, and we have the responsibility to do it. Let’s go work 
even harder,” he said.

Wardle is skeptical. “That’s all well and good - but start by changing your 
platform.”
 