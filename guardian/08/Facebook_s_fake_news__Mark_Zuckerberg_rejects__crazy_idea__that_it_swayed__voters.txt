
Mark Zuckerberg has rejected the notion that fake news on Facebook 
<https://www.theguardian.com/technology/2016/nov/10/facebook-fake-news-election-conspiracy-theories>
 influenced the outcome of the US election, describing it as a “pretty crazy 
idea”.

“Voters make decisions based on their lived experience,” he said at the 
Techonomy conference near San Francisco on Thursday.

“There is a profound lack of empathy in asserting that the only reason someone 
could have voted the way they did is because they saw fake news,” he said, and 
anyone who believes that has “failed to internalize” the message supporters of
Donald Trump <https://www.theguardian.com/us-news/donaldtrump> sent during the 
election.

Facebook’s failure: did fake news and polarized politics get Trump elected?
 Read more  
<https://www.theguardian.com/technology/2016/nov/10/facebook-fake-news-election-conspiracy-theories>
He also rejected the idea that people’s news feeds are becoming increasingly 
personalized to the point that opposing views are no longer visible – a 
phenomenon known as the filter bubble.

“We’ve studied it a lot. I really care about this,” he said, adding that in 
order to have a good impact on the world he wants people to have a “diversity 
of information”.

He compared the current media landscape to 20 years ago when people only had 
access to a few major TV networks and newspapers. “You got all your news 
filtered through that.”

With Facebook <https://www.theguardian.com/technology/facebook>, he said, most 
users have friends who have different political views to their own. “Even if 
90% of your friends are Democrats, probably 10% are Republicans. Even if you 
live in some state or country you will know some people in another state, 
another country.”

“That means that the information you are getting through the social system is 
going to be inherently more diverse than you would have gotten through news 
stations.”

The problem is that people don’t “click on and engage” with content that 
doesn’t conform to their world view, according to a human tendency towards 
confirmation bias.

“It’s not that the diverse information isn’t there … but we haven’t got people 
to engage with it in higher proportions.”

The less people engage with the content, the less likely the newsfeed is to 
surface it.

“Our job, our goal is to help people see the content that’s going to be the 
most meaningful and interesting to them,” he said.
 