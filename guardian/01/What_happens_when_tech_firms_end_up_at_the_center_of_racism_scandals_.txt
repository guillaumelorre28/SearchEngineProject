
The racist posts on Nextdoor.com became so frequent that they started to make 
Shikira Porter feel physically ill.

Billed as a “private social network for your neighborhood”, Nextdoor allows 
users to write public messages to neighbors who have joined the site, which now 
has more than 110,000 local groups across the US. After Porter, who is black, 
signed up in her Oakland, California, neighborhood in 2013, she quickly 
discovered that many of her white neighbors were posting “crime and safety” 
alerts about “suspicious” people of color.

A black man in a hoodie. A Latino man “hiding near the bus stop”. A black 
salesman who might be a burglar.

“It’s incredibly toxic,” said Porter, 42, who said she has had migraines after 
arguing with racist users. “I just feel like I’m in a constant state of rage 
that I have to manage.”

Porter channeled her anger into Neighbors for Racial Justice, an advocacy 
group that has for years pushed Nextdoor to combatracial profiling 
<http://www.eastbayexpress.com/oakland/racial-profiling-via-nextdoorcom/Content?oid=4526919&showFullText=true>
.

Following intense scrutiny and negative press, the San Francisco-based startup 
this month introduced a number of product changes, including an algorithm that 
directs users to offer more detailed descriptions of suspicious activity, 
beyond, for example, “black man in hoodie”.

The Nextdoor conflict is the latest controversy in what has become something 
of a predictable pattern whenSilicon Valley 
<https://www.theguardian.com/technology/silicon-valley> tech companies find 
themselves at the center of scandals at the intersection of race, social 
justice and free speech. While some say Nextdoor has taken a bold and proactive 
step with its new features, the dispute sheds light on increasingly tense 
debates surrounding the ethical obligations of social media and sharing economy 
companies that are reinventing communication and reshaping industries.

To critics of corporations such as Facebook, Twitter 
<https://www.theguardian.com/technology/twitter> and Airbnb, the cycle of tech 
scandals has become frustratingly familiar: driven by profits and public 
relations, the firms refuse to make substantive changes, often at the expense 
of their most vulnerable users.

A ‘fundamental’ shift

Nextdoor claims its anti-profiling measures are radical changes that will 
dramatically reduce racism on the site. The concept behind the tweaks, however, 
is fairly simple and rooted in ideas that California activistssuggested 
<http://www.eastbayexpress.com/SevenDays/archives/2015/10/28/nextdoorcom-executives-meet-with-oakland-activists-discuss-efforts-to-combat-racial-profiling>
 last fall.

Under the new system, before members can post a crime and safety message, the 
site warns them about profiling, saying: “Ask yourself – is what I saw actually 
suspicious, especially if I take race or ethnicity out of the equation?”

Next, users are encouraged to focus on behaviors and specific descriptions, 
such as clothing, shoes and tattoos. If they want to mention race, they have to 
fill out a form and include at least two other physical descriptors before 
posting.

“It’s unique for a tech company to fundamentally change its product,” Nextdoor 
CEO Nirav Tolia said in an interview.
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-2%23img-2&picture=https%3A%2F%2Fmedia.guim.co.uk%2F39cbd4d0b6106934b0a48db3b07f7b8b97576940%2F0_0_2048_1229%2F2048.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-2%23img-2>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3Fpage%3Dwith%3Aimg-2%23img-2&media=https%3A%2F%2Fmedia.guim.co.uk%2F39cbd4d0b6106934b0a48db3b07f7b8b97576940%2F0_0_2048_1229%2F2048.jpg>
 Racial profiling product improvements on Nextdoor. Photograph: Courtesy of 
Nextdoor 
After testing the tool, an internal study found that the algorithm reduced 
incidents of racial profiling by 75%, according to Tolia. Perhaps more 
significantly, many users are choosing not to post all, with a 50% increase in 
people deciding not to publish their crime and safety messages.

That drop in activity is a “completely worthy cost relative to the benefit”, 
Tolia said.

Activists say the changes are long overdue and don’t go far enough. Porter, 
for example, shared a recent post that simply described a “HMA” suspect, 
referring to “Hispanic male adult”.

But some tech critics said Nextdoor deserves credit for taking a risky step 
that may reduce overall posts and engagement.

“They’re creating friction. They’re making it a little harder to use their 
platform,” said Jamila Jefferson-Jones, associate professor of law at the 
University Missouri, Kansas City, who haswritten 
<http://urbanlawjournal.com/shut-out-of-airbnb-a-proposal-for-remedying-housing-discrimination-in-the-modern-sharing-economy/>
 about discrimination and technology. “But in the end, they’re getting better 
information.”

On the contrary, tech companies typically prioritize user-friendliness and 
convenience above all else – even if that means shielding racist users and 
allowing offensive posts.
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-3%23img-3&picture=https%3A%2F%2Fmedia.guim.co.uk%2F058429f5526c67be1587f9681369ad348da309a4%2F0_55_2048_1229%2F2048.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-3%23img-3>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3Fpage%3Dwith%3Aimg-3%23img-3&media=https%3A%2F%2Fmedia.guim.co.uk%2F058429f5526c67be1587f9681369ad348da309a4%2F0_55_2048_1229%2F2048.jpg>
 Racial profiling product improvements on Nextdoor. Photograph: Courtesy of 
Nextdoor 
‘We know how to fix the problem’

Airbnb, the popular home-sharing startup, has increasingly battled negative 
headlines aboutdiscrimination on its site 
<https://www.theguardian.com/technology/2016/may/05/airbnbwhileblack-hashtag-highlights-potential-racial-bias-rental-app>
. Independentresearch 
<http://www.benedelman.org/publications/airbnb-guest-discrimination-2016-01-06.pdf>
 has found that guests with “distinctively African American names” are 16% less 
likely to be accepted than identical guests with white-sounding names.

The San Francisco tech company announced this summer that it has hired former 
US attorney general Eric Holder 
<https://www.theguardian.com/technology/2016/jul/20/airbnb-hires-eric-holder-racial-discrimination-bias>
 to help address racism on the site.

The scandal, amplified by the hashtag #AirbnbWhileBlack, has prompted an 
aggressivePR response 
<http://blog.airbnb.com/an-update-on-the-airbnb-anti-discrimination-review/>, 
with CEO Brian Chesky claiming that the issue constitutes “the greatest 
challenge we face as a company”.

Researchers, however, say there are relatively simple fixes Airbnb 
<https://www.theguardian.com/technology/airbnb> could make but that the firm 
may be resistant to adopt – out of fear that it would reduce usage.

“They put out a lot of press releases relative to the amount of work they do 
and relative to the amount of changes they make,” said Ben Edelman, associate 
professor at Harvard Business School, who hasstudied Airbnb 
<https://www.theguardian.com/technology/2016/jul/27/airbnb-panel-democratic-national-convention-survey>
 anddiscrimination 
<http://hbswk.hbs.edu/item/uncovering-racial-discrimination-in-the-sharing-economy>
.

If Airbnb stopped having users display their names and faces and instead had 
them use anonymous screen names, it would go a long way toward reducing 
discrimination, Edelman said. “We know exactly how to fix the problem.”

 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-4%23img-4&picture=https%3A%2F%2Fmedia.guim.co.uk%2Fe939cf12cc6c4d8a2d866b3888ffe69b3a67358c%2F0_323_4928_2957%2F4928.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-4%23img-4>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3Fpage%3Dwith%3Aimg-4%23img-4&media=https%3A%2F%2Fmedia.guim.co.uk%2Fe939cf12cc6c4d8a2d866b3888ffe69b3a67358c%2F0_323_4928_2957%2F4928.jpg>
 Airbnb has increasingly battled negative headlines aboutdiscrimination on its 
site 
<https://www.theguardian.com/technology/2016/may/05/airbnbwhileblack-hashtag-highlights-potential-racial-bias-rental-app>
. Photograph: Martin Bureau/AFP/Getty Images 
In blind auditions where musicians can’t be seen, for example, orchestras hire 
more women and people of color, he noted.

Jefferson-Jones said Airbnb could also audit users and ban hosts who have 
faced repeated discrimination complaints or have a history of rejecting black 
users.

Fewer users, however, means reduced profit.

Nancy Leong, a University of Denver law professor, said that companies such as 
Airbnb are also concerned about legal liability, which makes them less likely 
to acknowledge major problems in the first place. “Lawyers are trying to advise 
clients to say as little as possible and to issue statements that are fairly 
generic.”

An Airbnb spokesman declined to comment on the suggestion of removing faces 
and names from the system, saying in a statement: “We are committed to fighting 
discrimination and earlier this summer, we launched a comprehensive review of 
every part of our platform.”

Why diversity matters

In the wake of a high-profile crisis, tech companies often focus on PR and 
liability as opposed to the experience of everyday users. As a result, regular 
people suffer, advocates said.

Facebook and Twitter have both experienced major scandals regarding 
harassment, bullying andabuse 
<https://www.theguardian.com/money/work-blog/2012/may/01/antisocial-network-facebook-abuse-employers>
 on their sites. Twitter in particular has been dogged by complaints that women 
and people of color on the site, especially outspoken activists and 
celebrities, are forced to reckon withviolent hate speech 
<https://www.theguardian.com/commentisfree/2016/jul/19/leslie-jones-twitter-abuse-deliberate-campaign-hate>
 and persistent threats.

After a wave of critical news stories, Twitter recently banned a rightwing 
writer 
<https://www.theguardian.com/technology/2016/jul/20/milo-yiannopoulos-nero-permanently-banned-twitter>
 who launched a coordinated attack against black comedian Leslie Jones, but 
many pointed out that the company has systematically failed non-celebrity women 
on the site facing similar abuse.

Critics have further noted that Twitter has been successful and eager to 
protect brands 
<https://www.buzzfeed.com/rossalynwarren/i-cant-believe-they-deleted-that-perfect-santana-tweet>
, aggressively removing posts that constitute copyright infringement.

Milo Yiannopoulos, rightwing writer, permanently banned from Twitter
 Read more  
<https://www.theguardian.com/technology/2016/jul/20/milo-yiannopoulos-nero-permanently-banned-twitter>
Part of the problem is that some of the social media scandals delve into 
uncharted territory where there aren’t clear or easy solutions. After Facebook 
faced accusations that it was biased towardspromoting liberal news sources 
<https://www.theguardian.com/technology/2016/may/12/facebook-trending-news-leaked-documents-editor-guidelines>
, the companyfired members 
<https://www.theguardian.com/technology/2016/aug/29/facebook-fires-trending-topics-team-algorithm>
 of its so-called trending team and left an algorithm to highlight popular news 
stories.

The result was Facebook promoting a false story about Fox News host Megyn 
Kelly and links to an article about a man masturbating with a McDonald’s 
sandwich.

While the trending topics PR debacle perhaps signals a lack of foresight in 
response to a scandal in the media, others argued that the poor responses to 
controversy stem from systemic problems.
 <> Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_fb%26page%3Dwith%3Aimg-5%23img-5&picture=https%3A%2F%2Fmedia.guim.co.uk%2Fd1597a716e0fbb8f290cbb9faae186dc02074c90%2F0_58_2100_1261%2F2100.jpg>
Twitter  
<https://twitter.com/intent/tweet?text=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3FCMP%3Dshare_btn_tw%26page%3Dwith%3Aimg-5%23img-5>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=What%20happens%20when%20tech%20firms%20end%20up%20at%20the%20center%20of%20racism%20scandals%3F&url=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2016%2Faug%2F30%2Ftech-companies-racial-discrimination-nextdoor-airbnb%3Fpage%3Dwith%3Aimg-5%23img-5&media=https%3A%2F%2Fmedia.guim.co.uk%2Fd1597a716e0fbb8f290cbb9faae186dc02074c90%2F0_58_2100_1261%2F2100.jpg>
 Malkia Cyril: ‘The investors are wealthy. They are white. And they are mostly 
men.’ Photograph: Center for Media Justice 
In particular, when tech companies lack diversity, especially in leadership 
positions, they can be unprepared to respond to serious and complex challenges 
that affect marginalized groups.

At Facebook, black employees account for only 3% of senior leadership 
<https://www.theguardian.com/technology/2016/jul/14/facebook-diversity-report-silicon-valley-employment>
 in the US.

Activists said that disparity was hard to ignore in the context of Facebook’s 
most recent controversy regarding racial inequities. Earlier this month, social 
justice advocatesslammed Facebook 
<https://www.theguardian.com/technology/2016/aug/24/facebook-live-anti-censorship-policy-korryn-gaines-letter>
 after the company, reportedly at the request of police,shut down the 
live-stream 
<https://www.theguardian.com/us-news/2016/aug/03/korryn-gaines-facebook-account-baltimore-police>
 of Korryn Gaines, a Baltimore woman in a standoff with officers. The police 
eventuallykilled her 
<https://www.theguardian.com/us-news/2016/aug/05/korryn-gaines-baltimore-lead-poisoning-crisis>
.

“I really hope that Facebook goes through a serious re-evaluation process of 
where their values lie,” said Taina Vargas-Edmond, state campaigner with the 
Ella Baker Center for Human Rights, which co-signed aletter 
<https://s3.amazonaws.com/s3.sumofus.org/images/FinalLetter-MarkZuckerberg_1.pdf>
 to Facebook condemning censorship of Gaines.

Facebook declined to comment on Gaines’s account.

Malkia Cyril, executive director of the Center for Media Justice, noted that 
one possible reason why Nextdoor has been more aggressive in responding to 
concerns of racial justice is that Tolia, its CEO, is a person of color. “The 
CEO has some empathetic understanding of what is happening here.”

Cyril, who is active in Black Lives Matter and has spoken out about online 
harassment 
<https://www.theguardian.com/technology/2016/apr/11/women-online-abuse-threat-racist>
 anddiversity in tech 
<https://www.theguardian.com/us-news/2016/jul/12/black-lives-matter-marc-benioff-facebook-twitter-uber>
, noted that many tech leaders prioritize the concerns of investors over users 
– even in the face of scandal.

 “The investors are wealthy. They are white. And they are mostly men.”
 