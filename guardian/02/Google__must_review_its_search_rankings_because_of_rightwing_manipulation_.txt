
Google <https://www.theguardian.com/technology/google> must urgently review 
its search ranking system because of “compelling” evidence that it is being 
“manipulated and controlled” by rightwing propagandists, leading academics have 
said, after the Observer reported that hate sites are now dominating searches 
on Muslims, Jews, Hitler and women.


Cathy O’Neil, a data scientist and the author of Weapons on Math Destruction 
<https://www.theguardian.com/books/2016/oct/27/cathy-oneil-weapons-of-math-destruction-algorithms-big-data>
, said that unless Google acknowledged responsibility for the problem, it would 
be a “co-conspirator” with the propagandists. “This is the end for Google 
pretending to be a neutral platform,” she said. “It clearly has a terrible 
problem here and it has to own and acknowledge that.


“It simply can’t go on pretending that it has no editorial responsibilities 
when it is delivering these kinds of results. It is simply not defensible for 
it go on claiming ‘plausible deniability’. It has clearly become a conduit for 
rightwing hate sites and it must urgently take action.”

Google alters search autocomplete to remove 'are Jews evil' suggestion
 Read more  
<https://www.theguardian.com/technology/2016/dec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion>
The Observer found that searches 
<https://www.theguardian.com/technology/2016/dec/04/google-democracy-truth-internet-search-facebook>
 for “are jews” were offering the suggestion “are jews evil”, and nine out of 
the 10 top results gave links to rightwing antisemitic hate sites. Google 
refused to comment on the individual search results, but on Sunday, itmoved to 
change some 
<https://www.theguardian.com/technology/2016/dec/05/google-alters-search-autocomplete-remove-are-jews-evil-suggestion>
 but not all of the autocomplete suggestions that the report highlighted.

Frank Pasquale, professor of law at Maryland University, said he found this “a 
very troubling and disturbing development”. “They’ve gone on in the fly and 
plugged the plug on certain search terms in response to your article, but this 
raises bigger and more difficult questions. Who did that? And how did they 
decide? Who’s in charge of these decisions? And what will they do in the 
future? This is clearly just being done in response to a story in the media, 
but it’s not accountable, and it’s not sustainable. I find it really troubling 
that they’ve taken this very quick and hasty response without any explanation 
of how and why they’ve done it.”

Google had removed the lines suggesting that Jews and black people are evil 
and that blacks “commit more crimes”, but it is still suggesting Muslims were 
“bad” and that Islam “should be destroyed”. While Facebook has faced criticism 
in the wake of revelations about how thesite had become a conduit for fake news 
<https://www.theguardian.com/technology/2016/nov/29/facebook-fake-news-problem-experts-pitch-ideas-algorithms>
, the problem facing Google is potentially even more intractable.

O’Neil said that she believed Google would ultimately have to hire human 
editors. She said: “There’s a a growing list of social media empires that have 
been attempting with all their power and might to claim that they don’t have 
editorial responsibility, but they have been proven wrong.

“They have been proven wrong by this troll army, and quite clearly when it 
comes to the questions that require a subtle understanding of the truth versus 
lies, they are going to have to use human judgment.

“It is clearly very frightening what is going on here. Google has done a huge 
amount of work to avoid exactly this scenario. And yet the troll army has still 
managed to break through all its resources and defences. It is very troubling 
and they are clearly very, very good at this, but it’s why Google has to own 
this problem. It is doing a terrible job here.

“Twenty years ago, these sites with these views … they would have been 
completely shut out by the mainstream press, but we have replaced our guardians 
of information with algorithms that are dumb and that can be toyed with and 
manipulated.”

Jonathan Albright, assistant professor of communications at Elon University, 
North Carolina, said that rightwing websites had launched a new “information 
war”, and that that they were winning. His research has shown that fake news 
and extremist sites have created a vast network of links to each other and 
mainstream sites that has enabled them to game Google’s algorithm. The top 
eight out of 10 results for the Google search “was Hitler bad?”, for example, 
are links to Holocaust denial sites including the neo-Nazi site, StormFront.org.

Albright’s research has shown that fake news and information is a far bigger 
structural problem than had been previously realised. He has mapped a “vast 
satellite system that is encroaching on the mainstream news system”. Websites 
propagating extreme rightwing propaganda have thrown out thousands of 
hyperlinks that connect to each other and to mainstream news sources, such as 
YouTube andFacebook <https://www.theguardian.com/technology/facebook>, and he 
says they “are growing in strength and influence every day”.

Julia Powles, a researcher at Cambridge University on technology and law, said 
Google’s response to the problem was “the classic PR response”. She added: “The 
media makes a fuss about something. Google goes in and hand-tweaks the result, 
while still claiming that it is not an editor and it is totally neutral, when 
clearly that is not true. It can and does change search results when it suits 
them.

Google, democracy and the truth about internet search
 Read more  
<https://www.theguardian.com/technology/2016/dec/04/google-democracy-truth-internet-search-facebook>
“They keep using this analogy that they’re like a card catalogue, but they’re 
really more like a card shark that can be gamed. It raises deeply disturbing 
issues about the democratic distribution of information.”

A Google spokesperson said: “We took action within hours of being notified on 
Friday of the autocomplete results.” Google did not comment on its decision to 
alter some but not all those results raised in the article.


It said: “Our search results are a reflection of the content across the web. 
This means that sometimes, unpleasant portrayals of sensitive subject-matter 
online can affect what search results appear for a given query. These results 
don’t reflect Google’s own opinions or beliefs. As a company, we strongly value 
a diversity of perspectives, ideas and cultures.”


Danny Sullivan, the editor of Search Engine Land and one of the leading 
authorities on Google search, said Google faced a “very difficult, very 
challenging issue”. “They’ve done the PR of getting rid of some of the bad 
stuff quickly, and they will hope the PR spin will help this go away, but it 
doesn’t take away from the bigger issues. I take the concern very deeply. 
Google is the universal resource that people turn to. It is a concern they 
really need to solve.”
 