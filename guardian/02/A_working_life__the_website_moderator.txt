
A vase containing two red gerberas sits on the window sill of Dawn Kitchener's 
home office. Behind the half-open slatted blinds, in the streets of Shepperton, 
south-west London, it's a cold, still morning. But on the laptop in front of 
us, an animated bulletin board discussion about dangerous dogs is rising to the 
boil.

"Michelle you are speaking a load of crap excuse the language!!" one poster 
writes. "I have a staff and she is the most lovable dog I know! By suggesting 
staffies need to be seized will only heighten illegal dog breeding … Grow up 
woman, and think about what you write!" Another poster adds: "All I wanna say 
is that it's not the dogs it's their bloody owners look at these gangs just 
have dogs 2 attack people and they just hav [sic] a fine instead of going 2 
prison." The laptop chimes soothingly as more and more comments appear on 
screen.

Kitchener observes this robust exchange of views, hosted on the website of the 
ITV1 programmeThis Morning <http://www.itv.com/thismorning/thehub/>, with a 
mild detachment, knowing that before long she will leave an indelible mark on 
the discussion, even if none of her opinions will be on view.

"This one that says 'crap'," she explains, matter-of-factly, "I know I'll just 
delete that straight away."

As a moderator, it is Kitchener's job to sanitise internet discussion threads 
on topics ranging from car dealerships to current affairs. Her employer, a 
company calledeModeration <http://emoderation.com/>, offers this service to 
some of the world's best-known brands, all of whom wish to join in with the 
social media revolution without exposing themselves to unwanted reputational 
damage.

It is a role she has been in for around five years, taking her neatly from the 
early days of social media use to the current proliferation of online 
networking, a world in which Facebook and Twitter collectively reach 1.1 
billion users. Not so long ago, most of Kitchener's work would have involved 
intercepting comments on internet messageboards or forums before they could be 
seen publicly. "The nub of what I'm doing is making sure nothing libellous is 
said or illegal is posted," she explains, "So obviously from that point of 
view, premoderated forums were much better. You could keep them quite safe, 
quite clean. And they would develop into real communities."

Yet as she points out, sounding a little regretful, the social media explosion 
has moved things on. Comments now go up instantaneously and it is her job to 
remove anything contentious as quickly as possible. "Now people want responses 
straight away, don't they?" she reflects. "Part of what I do is about managing 
that for clients."

We peer at Kitchener's special moderator's view of comments, in which 
sensitive words are highlighted in red, such as "crap", "teenage" and even 
"hun" – an abbreviation of "honey", I'm relieved to note, rather than a 
reference to wartime Germany.

Quickly it becomes apparent that, in the squeaky clean corporate world, 
anything contentious gets removed without a second thought. Only occasionally 
does Kitchener need to exercise judgment. "Maybe the word 'drugs' has been 
highlighted and it might be fine," she says. "But it might be that someone's 
said, 'Oh, one of the presenters looks like they're on drugs today.'" 
Momentarily I find it difficult to shake this image. "Obviously we'd have to 
remove that," she says firmly.

While most of her work is taken up with weeding out mild offence, there are 
also times, especially on a topical discussion show like This Morning, when the 
conversation can take a darker turn.

"It really depends on the news," she says. "If something happens and gets 
featured on the programme, you might get lots of racist comments coming in, for 
example."

Immediately I think of the recent Stephen Lawrence murder trial 
<https://www.theguardian.com/uk/lawrence>. In relation to that, was it 
necessary to censor many comments on racist grounds? "I don't know if you'd say 
a lot," she says picking her words carefully. "For something like the Lawrence 
case we'd probably have around 1,000 comments during the time it was being 
discussed on the TV, and you'd get maybe a couple of hundred that contained 
something unacceptable. But you'd get loads of arguing as well, someone 
sticking their neck out and saying something and then getting loads of support 
for it."

Often though, Kitchener points out, the most emotive topics have nothing to do 
with the news. One such example was a discussion about a man claiming to be 
"the vainest man in Britain", and here she cannot resist wading in and offering 
her own two penneth: "He got masses of abuse, because British people just don't 
like arrogance, do they? He was saying , 'I can have any woman I like', and 
people were going absolutely mad. That was probably one of the worst shifts." 
She shakes her head and laughs. "People were going on about this guy and what 
they'd do to him."

Her role in policing abusive posts goes no further than removing them and 
notifying the site provider that further investigation may be needed. 
Frequently abusive or baiting posters are warned and, eventually, have their 
accounts closed. "The problem with the internet is if you're banned, you can 
just recreate another user identity," she sighs. "That's why you constantly 
have to keep on top of it."

Crucially, Kitchener carries out all her moderating work from home. Prior to 
having children, she enjoyed a successful publishing career in London. But, as 
for many working mothers, child care and commuting became less and less 
compatible.

This led her to give up working altogether for a time, until a friend 
introduced her to eModeration. "They were looking specifically for a parent who 
could do five hours a week on a mother and baby site. So I thought that'd be 
perfect, just for a little bit of money on the side," she recalls.

The arrangement suited her well: "I loved it, reading this forum for pregnant 
mums and being able to do it from home. My youngest was about two at the time 
and I didn't really want to be working in town."

Since then she has taken on more projects, fitting them around the needs of 
her three children, all of whom are now established at school. Stacks of board 
games on shelves and brightly coloured drawings on the walls offer evidence of 
their existence, but otherwise the immaculately tidy house ("only because I 
knew you were coming," she insists) has a stillness to it that I find 
unsettling as one more accustomed to the buzz of an office.

I wonder if the anonymity and isolation can be lonely, but the solution, 
appropriately enough, lies in eModeration's network of 180 or so other 
home-based workers around the world. All are connected to instant messaging, 
Skype and email, as well as via a virtual office called Campfire, and actively 
encouraged to chat and support one another as though in a regular office 
environment. "Here," Kitchener points out, looking genuinely touched, 
"someone's put up a message saying Happy Peanut Butter Day!"

The humour and mutual support of her virtual colleagues is needed for the 
times when comments turn to sadder subjects such as child welfare or suicide 
threats, of which she says there are an increasing number.

"I have had two or three commenters saying, I don't want to go on any more," 
she says. "We would immediately escalate that. There's a procedure whereby we 
quickly flag it up to the client, so they can contact the user and get them 
some help."

Clearly there is good reason for many comments to be removed, but there also 
seems to be an aspect of this electronic hatchet work that goes against the 
community grain to which many discussion sites aspire.

Kitchener's anonymous interventions may, for example, be presented to by 
commenters without any explanation or context. One comment on her screen reads: 
"Why ask for our opinions if you're going to delete them … how rude!"

Similarly, she says the hardest part of handling a suicide-related post is 
never knowing the outcome. "It does affect you," she admits. "You're just left 
there thinking, I hope that person is all right."

The rotas of hourly shifts she works are plotted sensitively, giving 
moderators the chance to recover from potentially stressful projects by 
interspersing them with lighter-hearted ones. "I've never had to sit for eight 
hours reading really horrible stuff," she says.

Still, it feels like the beautifully sunny children's pictures around her 
workspace cast a light of their own on her desk. Kitchener thinks moderating, 
from a parental perspective, makes her more open minded: "You learn how to keep 
your kids safe. Otherwise, I don't think I'd know what goes on."

Warming to the theme, she sounds as if she might even be composing a comment 
of her own. "Once people are behind a computer, they can turn into monsters, 
saying things I don't think they'd ever say in real life," she says, before 
pausing to reflect. "It's a different world. You just have to look at it like 
that, I think."
 