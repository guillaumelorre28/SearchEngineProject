
When Joe Weizenbaum found his secretary using a computer program he had 
created, he was so upset he devoted the rest of his life to warning people not 
to use its technology. The program was “Eliza”, which gives a passable 
imitation of a nondirectional psychiatrist; you type sentences such as: “I 
wonder what I should write,” and it replies :“What answer would please you the 
most?” (You can try a version atpsych.fullerton.edu/mbirnbaum/psych101/Eliza.htm
 <http://psych.fullerton.edu/mbirnbaum/psych101/Eliza.htm>).

Weizenbaum’s distress came because he had written Eliza as an experiment, to 
see whether he could simulate “artificial intelligence” in a 
question-and-answer system by parsing sentences and throwing relevant bits back 
at the questioner. But his secretary saw it as real, and asked him not to 
intrude on “sessions”; Weizenbaum saw this as an omen that we would be too 
easily fooled into trusting machines.

The story dates from the 1960s (Weizenbaum died in March 2008), but is 
relevant today. Machine intelligence and machine learning – the new synonyms 
for “artificial intelligence” – are on the rise and are going to be pervasive. 
To some extent, anyone using a smartphone is already using some sort of machine 
intelligence with Google Now’s suggestions or Apple Maps’s determination of 
what counts as your “home” and “work”, or Windows Phone’s Cortana. We don’t 
call these “artificial intelligence”, because the moniker earned ridicule down 
the years. But it doesn’t matter what you call it; the ability to get computers 
to infer information that they aren’t directly supplied with, and to act on 
that, is already here. TakeGoogle 
<https://www.theguardian.com/technology/google> Photos, released in May, which 
can figure out that you were taking photos of a zombie parade, or find pictures 
of canoes, or - well, pretty much anything. It’s not limited to human faces 
(though it can do those, and distinguish between children and babies). If you 
don’t want to know about deep-learning neural networks, then it satisfies 
Arthur C Clarke’s dictum: “Any sufficiently advanced technology is 
indistinguishable from magic.”

Part of the magic behind Google Photos comes from a British company, DeepMind 
Technologies, which built what it calls “artificial generalised intelligence”. 
They trained it on video games such asSpace Invaders and Breakout; it got 
amazingly good at them after a few hundred games, without any special training. 
DeepMind isn’t the only machine learning company Google has acquired; last 
Augustit bought Jetpac 
<https://www.theguardian.com/technology/2014/aug/18/google-buys-neural-network-city-guide-creator-jetpac>
, which used neural networks to figure out what was in your holiday photos.

The promise of such machine learning is hugely exciting, and not limited to 
Google. Jetpac’s creator Pete Warden wrote a fun app calledDeep Belief 
<https://github.com/jetpacapp/DeepBeliefSDK/> which you could download for iOS 
that used neural networks to try to identify what the camera was seeing. . 
There’s an open-source machine learning framework calledSeldon 
<http://www.seldon.io/>. Another AI system called Snips <http://snips.net/beta> 
now in beta (http://snips.net/beta), aims to put a personalised AI – a “smart 
assistant” – on your phone.

It’s that latter idea that’s the real promise. Eliza used to require a 
mainframe; modern machines can run it as an applet without breaking sweat. Deep 
Belief shows that neural networks can run on modern smartphones. Give it a few 
years, and your smartphone’s AI will have power enough to understand the 
context of what you’re doing, figure out how it should help (call or text 
people to say you’re late? Understand whose emails you do and don’t want to 
receive at particular times? Find the right people for you to link up with on 
social media?) and act on it. You’ll be able to choose whether you want that 
done by an “assistant” on your phone, or in the cloud. The cloud-based one will 
be smarter, because it will have access to much more data; the phone-based one 
will be much more personal, and function even without a network connection.

Weizenbaum feared that AI couldn’t be trusted with decisions because it 
wouldn’t have empathy or compassion. But that’s fine. It’s the everyday grind 
that AI can smooth. I, for one, welcome our new robot underlings.
 