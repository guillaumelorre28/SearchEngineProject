
The 2015 Program for International Student Assessment (Pisa) 
<http://www.oecd.org/pisa/> results have been released - and on first glance, 
it does not look good for Australia.

On global comparisons, Australia performed equal 10th in science (down from 
8th in 2012), 20th in maths (down from 17th) and 12th in reading (down from 
10th).

There is a steady decline in the results since 2000, both in terms of overly 
simple international comparisons and absolute mean scores.

No doubt, similar to the response to Trends in International Mathematics and 
Science Study (Timss)results last week 
<https://theconversation.com/australian-schools-continue-to-fall-behind-other-countries-in-maths-and-science-69341>
, the media, politicians and education commentators will go into a panic over 
Australiasliding down 
<http://www.theaustralian.com.au/national-affairs/education/students-slide-in-global-maths-and-science-rankings/news-story/bf2aa8be9b40805d6d9406c4392a3940>
 the international rankings,falling standards 
<http://www.heraldsun.com.au/news/opinion/kevin-donnelly-teach-kids-the-basics-or-theyll-stay-mediocre/news-story/4d14d47854c7e546a1323a8dd745654f>
 in classrooms, andpoor quality teachers 
<http://www.couriermail.com.au/news/opinion/modern-teaching-methods-not-working-in-a-system-infused-with-leftist-ideology/news-story/c7b504491c30f3e405d8f0df97895f05>
.


Beyond the panicked headlines 
<https://theconversation.com/governments-need-to-look-beyond-education-rankings-and-focus-on-inequities-in-the-system-69715>
, what can we actually learn from the results of an international test that 
compares 15 year olds’ science, maths and reading skills in 72 countries and 
economies?

We need to have a more considered discussion about these test results rather 
than leaping to quick conclusions about a failing education system.

Scientific literacy

The main domain of the 2015 test was scientific literacy - the application of 
scientific knowledge and skills to solve problems.

Australia’s average score was 510, significantly above the OECD average of 493.

However, there has been an overall decline of 17 points since 2006. With the 
exception of the Northern Territory and Tasmania, most states performed well 
above the OECD average.

Singapore achieved the highest score of 556, which equates to roughly one and 
a half years more schooling than Australia.

While 61% of Australian students achieved the National Proficient Standard, 
only 11% were high performers (OECD average was 8%) and 18% were low performers 
(OECD average was 21%). This suggests that the majority of students might be 
doing okay, but few are excelling.

Mathematical literacy

The OECD average for mathematical literacy was 490, with Australia achieving 
494. This is significantly below 19 other countries, including Singapore at 564 
points. This is the equivalent of two and a half years more schooling.

The number of students reaching the National Proficient Standard in 
mathematical literacy was 61% in the Australian Capital Territory, but only 44% 
in Tasmania.

Reading literacy

Singapore achieved the highest result of 535 in reading literacy, equating to 
about one year more of schooling than Australia’s score of 503. The OECD 
average was 493.

Once again, the Northern Territory and Tasmania performed significantly below 
the OECD average, while all other states gained much higher results. Also, the 
spread between the lowest and highest Australian performers was significantly 
wider than the OECD average.

What the results mean

It is unhelpful to use the single country ranking to determine how we are 
going as there are significant variances between states/territories and school 
sectors (government, independent, Catholic).

Instead, we need to carefully disaggregate the data and consider the social 
and economic factors that influence performance across states, between schools, 
as well as the correlations between gender, Indigeneity, class, race, 
geographical location, and so on.

Australia has one of the widest ranges of student achievement, with what can 
be described as a long tail of underachievement.

For example, the difference in performance of students from the Australian 
Capital Territory and those in Tasmania and the Northern Territory is worth 
considering.

These differences are similar to those evident in performance on National 
Assessment Program – Literacy and Numeracy (NAPLAN) 
<https://theconversation.com/naplans-tale-of-two-territories-why-act-and-nt-are-on-opposite-ends-of-the-spectrum-45696>
.

Furthermore, there is a difference of nearly three years of schooling between 
students in the highest socioeconomic quartile and the lowest, with similar 
differences when comparing Indigenous with non-Indigenous students.

Interestingly, boys only marginally outperformed girls on scientific literacy, 
with girls significantly outperforming boys on reading literacy, with no real 
difference on mathematical literacy.

It is also interesting to note that since the Pisa tests began in 2000, the 
major federal education policy levers have included:

 * Significantly increased federal funding to private schools under John 
Howard, followed by a commitment by Julia Gillard that no school would lose a 
dollar. 
 * Failure to implement Gonski’s needs-based funding of all schools. 
 * The introduction of Naplan, MySchool, the Australian Curriculum and the 
AITSL national teaching standards by the Rudd-Gillard governments. 
 * Increased emphasis on market measures for school provision, such as 
Independent Public Schools and school autonomy. 
Yet over this time, the narrative of steady decline on Pisa and Timss results 
continues, while educational inequality is on the rise.

Australia has one of the most segregated schooling systems in the world, and 
the OECD data provide a strong correlation between high-performing systems such 
as Singapore and factors of social cohesion and equity.

Further evidenced in secondary analysis of all Pisa data over time is the 
strength of the correlation between equitable funding of schools and systemic 
performance on Pisa.

If we want to address these sliding results then we must address the issue of 
educational inequality in Australia.

Social efficiency and social equity

There are competing tensions in the agenda of social efficiency and social 
equity <https://books.google.com.au/books?id=KlnhgWecmlUC>, which is evident in 
how Pisa results inform global and local education policy-making. This includes 
the emphasis on competing within a global knowledge economy.

It is worth noting how the economic rationalisation for greater educational 
equity plays out in theglobal policy field 
<http://www.tandfonline.com/doi/abs/10.1080/01425692.2014.919846>, particularly 
through testing regimes such as Naplan and Pisa.

The challenge for policymakers, schools and teachers is how to respond to 
increasing pressure to lift test results on Pisa, Timss and Naplan, while also
addressing systemic inequality 
<https://theconversation.com/governments-need-to-look-beyond-education-rankings-and-focus-on-inequities-in-the-system-69715>
 in order to ensure that every Australian student is given access to a 
meaningful education.

Equitable funding of schools, including redistribution to schools serving 
disadvantaged communities, remains a pressing policy issue in Australia.

However, it is unlikely that we will see much more than panic and moral 
crusading in the media commentary over the coming days.

Once the hyperventilating dies down, we need to take a long, careful look at 
these results and what they mean for a more equitable and high-performing 
Australian schooling system.

• Stewart Riddle <https://theconversation.com/profiles/stewart-riddle-66963> 
is a Senior Lecturer at the University of Southern Queensland andBob Lingard 
<https://theconversation.com/profiles/bob-lingard-110661> is a professorial 
research fellow at the school of education at the University of Queensland. 
This article has beenrepublished from the Conversation 
<https://theconversation.com/pisa-results-dont-look-good-but-before-we-panic-lets-look-at-what-we-can-learn-from-the-latest-test-69470?utm_medium=email&utm_campaign=Latest%20from%20The%20Conversation%20for%20December%207%202016%20-%206242&utm_content=Latest%20from%20The%20Conversation%20for%20December%207%202016%20-%206242+CID_e939e878ef1ecb5471860bf0287ecc01&utm_source=campaign_monitor&utm_term=PISA%20results%20dont%20look%20good%20but%20before%20we%20panic%20lets%20look%20at%20what%20we%20can%20learn%20from%20the%20latest%20test>
 