
One of the fringe benefits of being the Guardian's crossword editor is the 
(usually friendly) conversations that I get into with complete strangers. One 
claim that comes up quite often in these chance conversations is that the 
cryptic puzzles have been getting more difficult over recent years.

If they have, this is certainly not the result of any policy shift. And I am 
not sure how you would set about trying to decide on an objective measure of 
crossword difficulty. The numbers of those submitting entries for the Saturday 
prize puzzle (which is consciously pitched a bit harder than average) remain 
pretty steady at between 1,500 and 2,000 a week; very seldom is the figure 
either higher or lower.

But the number of entries for the Saturday puzzle is no measure of how many 
people complete it without sending it in, let alone of how difficult the 
average solver found it. For the other five crossword days of the week, we have 
no measure at all. All I have to guide me is sparse anecdotal evidence, usually 
gathered as a result of these encounters.

There is obviously the potential danger that regular setters will drift 
unconsciously in the direction of writing harder clues. Compilers would not be 
human if they did not feel the temptation to bowl the odd unplayable bouncer 
just to break the routine of deliveries with a steady length and direction. 
Also, a new compiler can cause solvers problems to begin with, in the same way 
that a new bowler can unsettle a batsman. But the intention, at least, is that 
the paper's daily cryptic puzzles should set fair tests that can be passed, 
with a bit of concentration, by persons of normal IQ and average erudition.

Though the policy is that these daily tests should be fair, they are 
deliberately set at varying levels of difficulty. Last September, I set out the 
(entirely subjective) evaluation of our compilers that I use in seeking to 
balance each week's batch of crosswords between fairly easy, middling and 
fairly difficult. I said that I would be interested to know what others thought.

The only piece of evidence that I have that is based on what a social 
scientist would call quantitative data is from a regular solver in southwest 
London. Over a period of 10 months, he kept a record of the puzzles he managed 
to complete successfully (255 puzzles were involved in the experiment). He 
seems to have spent roughly the same (unspecified) time each day on the cryptic 
puzzle before giving up, if he had not completed it. (The limitation of this 
ground breaking research, of course, is that each day's entry gives just a 
binary result: completed or not completed. So a puzzle finished except for one 
clue is in the same category as a puzzle where not a single clue could be 
solved.)

Here (in percentages of a compiler's puzzles completed) are the Lambeth 
solver's main results:

 100%: Auster, Audreus 
75-80%: Janus, Logodaedalus, Quantum 
56%: Rufus 
45%: Shed 
40%: Orlando 
33%: Araucaria, Gordius 
25%: Rover 
16%: Chifonie 
12%: Pasquale, Taupi 
Less than 7%: Bunthorne, Enigmatist, Paul

On the assumption that the above figures are some kind of measure of the 
degree of difficulty of individual compilers, it might be of interest if I gave 
the number of times each compiler's work appeared in calendar 2003: Araucaria 
45, Paul 40, Rufus 38, Gordius and Shed 24, Bunthorne 23, Janus 12, Crispa and 
Orlando 11, Pasquale, Rover and Taupi 10, Chifonie, Enigmatist and Quantum 9, 
Logodaedalus 8, others less than 6.

----------

Enough figures! Here's a final note on something completely different. When 
the current round of University Challenge is over (BBC2 Monday evenings), it 
will be followed by another round of University Challenge - the Professionals. 
A team of four crossword compilers has entered; three of whose bylines (if not 
faces) will be familiar to you. They are Bunthorne, Araucaria and Paul, plus 
Richard Browne (the crossword editor of The Times).

Neither our opponents nor the date we shall be broadcast are yet known, but 
filming is later this month in Manchester. The competition is tougher than for 
the university teams. I gather that there are to be 22 teams of "professionals" 
in the first round, from which only four (the highest scorers) go through to 
the semi-finals. So at least seven of the 11 teams that win on their first 
outing will not go through to the next round. And, in theory at least, a team 
could lose on the first night and still score high enough to end up in the 
semi-final. Watch the Radio Times for details!
 