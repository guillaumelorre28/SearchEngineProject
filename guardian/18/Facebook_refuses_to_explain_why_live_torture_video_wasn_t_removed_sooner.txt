
Facebook on Thursday refused to respond to mounting questions over its 
apparent failure to take down a live broadcast of thebrutal attack of a young 
man 
<https://www.theguardian.com/us-news/2017/jan/04/facebook-live-stream-video-man-attacked-chicago-trump>
 with disabilities in Chicago.


Four arrested over Facebook Live video of man tortured amid anti-Trump taunts
 Read more  
<https://www.theguardian.com/us-news/2017/jan/04/facebook-live-stream-video-man-attacked-chicago-trump>
Wednesday’s Facebook Live video showing a man bound 
<https://www.theguardian.com/us-news/2017/jan/04/facebook-live-stream-video-man-attacked-chicago-trump>
, gagged and cut with a knife amid shouts of “fuck Donald Trump” undermines the 
company’s efforts to market the tool.

For the last few months, Facebook has been running a multimedia advertising 
campaign encouraging users to try itsvideo live-streaming product 
<https://www.theguardian.com/technology/2017/jan/05/facebook-live-social-media-live-streaming>
.

On billboards, television and online the company uses cutesy animations urging 
users to share warm and fuzzy moments like “hanging out with friends” or “when 
you see someone walking an animal that’s not a dog”.


At no point does the company suggest using the tool to document torture 
<https://www.theguardian.com/us-news/2017/jan/04/facebook-live-stream-video-man-attacked-chicago-trump>
,police brutality 
<https://www.theguardian.com/us-news/philando-castile-shooting> or spree killing
 
<http://www.cbsnews.com/news/michael-vance-oklahoma-fugitive-posts-facebook-live-videos-while-on-run-report/>
 – but that is precisely what the tool has, in part, gained a reputation for 
over the last nine months.

This was brought to the fore most viscerally with this week’s attack in 
Chicago. The 30-minute assault was watched by 16,000 people, leaving many 
asking why Facebook didn’t take the content down as it did in the case of the
police standoff with Korryn Gaines 
<https://www.theguardian.com/us-news/2016/aug/03/korryn-gaines-facebook-account-baltimore-police>
. Facebook did eventually take down the recorded video, but not before it had 
been copied and widely shared on YouTube.

Facebook refused to comment on how many people – if any – reported the 
content, although there appear to have been many comments under the live stream 
made by horrified viewers who may have also used the report tool. Nor would
Facebook <https://www.theguardian.com/technology/facebook> tell the Guardian 
when it first became aware of the video and how long it took to decide to take 
the footage down from the site.

Instead, a spokeswoman for the company in a statement: “We do not allow people 
to celebrate or glorify crimes on Facebook and have removed the original video 
for this reason. In many instances, though, when people share this type of 
content, they are doing so to condemn violence or raise awareness about it. In 
that case, the video would be allowed.”

Facebook also pointed to a blogpost about  community standards for Live Video 
<http://newsroom.fb.com/news/h/community-standards-and-facebook-live/>, where 
it explains that it has a team on call 24 hours a day, seven days a week 
“dedicated to responding to reports” from users “immediately”.

Reviewers can interrupt a live video stream if it violates the community 
standards and it only takes one report for an item of content to be reviewed. 
The company also monitors videos if they reach a certain level of popularity, 
even if they haven’t been reported.

All of which raises difficult questions for Facebook about how the shocking 
video was broadcast, seemingly uninterrupted, for 30 minutes.

“I find it really hard to believe that not enough people reported it,” said 
Reem Suleiman of SumOfUs, a civil rights group that’s been campaigning for 
Facebook to bemore transparent about its content takedown process 
<https://www.theguardian.com/technology/2016/oct/31/facebook-human-rights-censorship-civil-rights-mark-zuckerberg-aclu>
.


“I don’t want to speculate here, but we’ve had issues ourselves trying to get 
certain things taken down in the past,” she added.

The unpredictable course of live streaming has caught us unprepared
 Read more  
<https://www.theguardian.com/media/2016/jul/17/live-streaming-violent-events-crisis-facebook>
As NPR highlighted in November 
<http://www.npr.org/sections/alltechconsidered/2016/11/17/495827410/from-hate-speech-to-fake-news-the-content-crisis-facing-mark-zuckerberg>
, the role of moderation is carried out by a team of subcontractors operating 
under pressure, making decisions about pieces of flagged content once every 10 
seconds. It’s no surprise that mistakes, such as the inappropriate censorship 
of acelebrated Vietnam War picture 
<https://www.theguardian.com/technology/2016/sep/08/facebook-mark-zuckerberg-napalm-girl-photo-vietnam-war>
 or abreast cancer awareness video 
<https://www.theguardian.com/technology/2016/oct/20/facebook-bans-swedish-breast-cancer-awareness-video-for-being-offensive>
, are made. Given the complexity and duration of live video streams, it’s 
difficult to see how they can be effectively assessed under these conditions.

Katy Culver, the director of the Center for Journalism Ethics, suggested that 
perhaps nobody reported the video to Facebook. “Otherwise, I struggle to 
believe that the platform would not have taken it down,” she said.

Police spokesman Anthony Guglielmi told the Guardian on Thursday that police 
learned of the Facebook video around the same time that the agency encountered 
the victim and quickly determined that he was the subject of the footage.

While patrol officers were assisting the victim, “other units had gotten word 
of the Facebook video”, he said. “It only took a matter of hours to put this 
whole case together.”
Guglielmi said police had no difficulties acquiring the video and did not make 
any formal requests to the social media company for help in securing evidence.

Four suspects have been charged 
<https://www.theguardian.com/us-news/2017/jan/05/facebook-live-beating-anti-donald-trump>
 with hate crimes, kidnapping, battery and burglary. Police identified the 
suspects as Jordan Hill, Tesfaye Cooper, Brittany Covington and Tanishia 
Covington. The suspects are all 18 years old, except Tanishia Covington, who is 
24, according to the Associated Press.

The incident once again raises questions about Facebook’s responsibility as a 
media company 
<https://www.theguardian.com/technology/2016/dec/12/facebook-2016-problems-fake-news-censorship>
. Just as critics are calling for the company to stop thespread of 
misinformation on its platform 
<https://www.theguardian.com/technology/2016/nov/10/facebook-fake-news-election-conspiracy-theories>
, so too are they demanding Facebook make editorial judgemnts about Live video.

“It’s a really good example of why Facebook cannot rely solely on its users to 
report content. It’s clearly not effective, it’s not good enough,” said 
Suleiman.
Facebook  
<https://www.facebook.com/dialog/share?app_id=180444840287&href=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2017%2Fjan%2F06%2Fobama-facebook-attack-terrible-but-not-sign-worsening-racial-tensions-video&picture=>
Twitter  
<https://twitter.com/intent/tweet?text=President%20Obama%3A%20Facebook%20Live%20attack%20shows%20'terrible%20toll'%20racism%20takes%20on%20families%20%E2%80%93%20video&url=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2017%2Fjan%2F06%2Fobama-facebook-attack-terrible-but-not-sign-worsening-racial-tensions-video>
Pinterest  
<http://www.pinterest.com/pin/create/button/?description=President%20Obama%3A%20Facebook%20Live%20attack%20shows%20%27terrible%20toll%27%20racism%20takes%20on%20families%20%E2%80%93%20video&url=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2Fvideo%2F2017%2Fjan%2F06%2Fobama-facebook-attack-terrible-but-not-sign-worsening-racial-tensions-video&media=>
President Obama: Facebook Live attack shows ‘terrible toll’ racism takes on 
families 
<https://www.theguardian.com/us-news/video/2017/jan/06/obama-facebook-attack-terrible-but-not-sign-worsening-racial-tensions-video>
She acknowledged that the live-streaming tool was valuable for exposing human 
rights abuses. “But there’s a huge difference between using Facebook to expose 
violence and corruption and using it to violate, exploit and abuse people,” she 
said.

“If Facebook wants people to use its platform to report news, it needs to be 
held to the same standard that other news outlets are.”

Others believe Facebook should be building better technical solutions for 
triaging problematic content.

“Facebook has to moderate horrifying levels of graphic and upsetting content 
that emerges around the world every day,” said Claire Wardle of First Draft 
News. “But this example shows how much further the company has to go in terms 
of improving their discovery technology to ensure a video like this gets pushed 
to the top of a moderation queue.”

Culver accepts that it is extremely challenging to monitor the volume of 
content posted to Facebook, but she said the social network appeared to be 
taking steps in the right direction.

“The course-correction they did on ‘fake news’ 
<https://www.theguardian.com/technology/2016/dec/15/facebook-flag-fake-news-fact-check>
 indicates they are thinking more about their responsibilities as a platform,” 
she said.

 * Facebook Live will change social media – but in what way? 
<https://www.theguardian.com/technology/2017/jan/05/facebook-live-social-media-live-streaming> 